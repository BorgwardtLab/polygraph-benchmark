{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, OrderedDict\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "from pyprojroot import here\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "\n",
    "with open(\"/fs/pool/pool-mlsb/polygraph/rcparams.json\", \"r\") as f:\n",
    "    style = json.load(f)\n",
    "\n",
    "\n",
    "MAIN_CLASSIFIER_TYPE = \"tabpfn\"\n",
    "classifiers_to_compare = (\"lr\", \"tabpfn\")\n",
    "\n",
    "meain_metric_dropdown = widgets.Dropdown(\n",
    "    options=['informedness', 'jsd'],\n",
    "    value='jsd',\n",
    "    description='Metric:',\n",
    ")\n",
    "\n",
    "plot_full_dropdown = widgets.Dropdown(\n",
    "    options=[True, False],\n",
    "    value=False,\n",
    "    description='Full plot:',\n",
    ")\n",
    "\n",
    "# Observe changes in dropdown value\n",
    "def on_metric_change(change):\n",
    "    global MAIN_METRIC_NAME\n",
    "    MAIN_METRIC_NAME = change.new\n",
    "    print(f\"Selected metric changed to: {MAIN_METRIC_NAME}\")\n",
    "\n",
    "def on_plot_full_change(change):    \n",
    "    global PLOT_FULL\n",
    "    PLOT_FULL = change.new\n",
    "    print(f\"Full plot changed to: {PLOT_FULL}\")\n",
    "\n",
    "meain_metric_dropdown.observe(on_metric_change, names='value')\n",
    "plot_full_dropdown.observe(on_plot_full_change, names='value')\n",
    "\n",
    "display(meain_metric_dropdown)\n",
    "display(plot_full_dropdown)\n",
    "\n",
    "MAIN_METRIC_NAME = meain_metric_dropdown.value\n",
    "PLOT_FULL = plot_full_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_FULL:\n",
    "    results_folder = \"/fs/pool/pool-mlsb/polygraph/perturbation_experiments/results_full\"\n",
    "else:\n",
    "    results_folder = \"/fs/pool/pool-mlsb/polygraph/perturbation_experiments/results_cropped\"\n",
    "\n",
    "def process_results(df, saturation_threshold=0.95, metric_name=\"informedness\", classifiers=(\"lr\", \"tabpfn\")):\n",
    "    # Find all columns that end with \"informedness\"\n",
    "    all_metrics = [\"jsd\", \"informedness\"]\n",
    "    all_classifier_cols = [col for col in df.columns if any(col.endswith(metric) for metric in all_metrics)]\n",
    "    main_metric_cols = [col for col in df.columns if col.endswith(metric_name)]\n",
    "    cols_to_drop = [col for col in all_classifier_cols if col not in main_metric_cols]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Informedness values are tuples (train, test)\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "    for col in main_metric_cols:\n",
    "        df[col] = df[col].apply(ast.literal_eval)\n",
    "        df_test[col] = df[col].apply(lambda x: x[1])\n",
    "        df_train[col] = df[col].apply(lambda x: x[0])\n",
    "    \n",
    "    # For each row, find which column obtains maximum train value\n",
    "    for classifier_type in classifiers:\n",
    "        classifier_cols = filter(lambda x: classifier_type in x, main_metric_cols)\n",
    "        optimal_descriptors = df_train[classifier_cols].idxmax(axis=1)\n",
    "        optimal_test_values = [df_test.loc[i][col] for i, col in enumerate(optimal_descriptors)]\n",
    "        df[f\"{classifier_type}_{metric_name}\"] = optimal_test_values\n",
    "\n",
    "    df[main_metric_cols] = df_test\n",
    "\n",
    "    main_metric_cols = main_metric_cols + [f\"{classifier_type}_{metric_name}\" for classifier_type in classifiers]\n",
    "\n",
    "    is_saturated = df[main_metric_cols] >= saturation_threshold\n",
    "    saturation_points = {}\n",
    "    for col in main_metric_cols:\n",
    "        arr = is_saturated[col].values\n",
    "        remains_saturated = np.cumprod(arr[::-1], axis=0)[::-1].astype(int)\n",
    "        saturation_points[col] = df[\"noise_level\"][remains_saturated.argmax().min()] if remains_saturated.any() else 1.0\n",
    "\n",
    "    return df, saturation_points\n",
    "\n",
    "perturbations = [\"edge_deletion\", \"edge_rewiring\", \"edge_swapping\", \"mixing\", \"edge_addition\"]\n",
    "datasets = [\"planar\", \"lobster\", \"proteins\", \"sbm\", \"ego\"]\n",
    "all_saturation_points = defaultdict(dict)\n",
    "\n",
    "all_dfs = defaultdict(dict)\n",
    "\n",
    "for perturbation, dataset in product(perturbations, datasets):\n",
    "    df = pd.read_csv(f\"{results_folder}/perturbation_{dataset}_{perturbation}.csv\")\n",
    "    df, saturation_points = process_results(df, metric_name=MAIN_METRIC_NAME, classifiers=classifiers_to_compare)\n",
    "\n",
    "    all_saturation_points[perturbation][dataset] = saturation_points[f\"{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\"]\n",
    "    all_dfs[perturbation][dataset] = df\n",
    "\n",
    "\n",
    "all_saturation_points = pd.DataFrame(all_saturation_points)\n",
    "all_saturation_points.to_csv(\"all_saturation_points.csv\")\n",
    "display(all_saturation_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Plots\n",
    "Below, we plot the correlation of the different metrics with the noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_descriptor_color(metric_name):\n",
    "    colors = sns.color_palette(\"colorblind\")\n",
    "    descriptor_colors = {\n",
    "        \"orbit\": colors[0],\n",
    "        \"degree\": colors[1],\n",
    "        \"spectral\": colors[2],\n",
    "        \"clustering\": colors[3],\n",
    "        \"gin\": colors[4],\n",
    "    }\n",
    "    for key, value in descriptor_colors.items():\n",
    "        if key in metric_name:\n",
    "            return value\n",
    "    assert metric_name in [f\"{classifier}_{metric}\" for classifier, metric in product([\"rbf\", \"lr\", \"tabpfn\"], [\"jsd\", \"informedness\"])], metric_name\n",
    "    return \"black\"\n",
    "\n",
    "def rbf_lr_color(metric_name):\n",
    "    colors = sns.color_palette(\"colorblind\")\n",
    "    if metric_name.startswith(\"lr_\"):\n",
    "        return colors[0]\n",
    "    elif metric_name.startswith(\"tabpfn_\"):\n",
    "        return colors[1]\n",
    "    elif metric_name.startswith(\"rbf_\"):\n",
    "        return colors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correlation_dfs = defaultdict(dict)\n",
    "\n",
    "for perturbation, dataset in product(perturbations, datasets):\n",
    "    all_correlation_dfs[perturbation][dataset] = all_dfs[perturbation][dataset].corr(\"spearman\")\n",
    "\n",
    "\n",
    "# Create a jitter plot\n",
    "metrics_to_compare = OrderedDict([\n",
    "    (\"orbit_rbf\", \"Orbit RBF\"),\n",
    "    (\"degree_rbf\", \"Deg. RBF\"),\n",
    "    (\"spectral_rbf\", \"Spec. RBF\"),\n",
    "    (\"clustering_rbf\", \"Clust. RBF\"),\n",
    "    (\"gin_rbf\", \"GIN RBF\"),\n",
    "    (f\"{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", \"PGS\"),\n",
    "])\n",
    "\n",
    "perturbations_to_plot = OrderedDict([\n",
    "    (\"edge_deletion\", \"Edge Deletion\"), \n",
    "    (\"edge_rewiring\", \"Edge Rewiring\"), \n",
    "    (\"edge_swapping\", \"Edge Swapping\"), \n",
    "    (\"mixing\", \"Mixing\"), \n",
    "    (\"edge_addition\", \"Edge Addition\"\n",
    ")])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(15, 3))\n",
    "\n",
    "for i, (perturbation, label) in enumerate(perturbations_to_plot.items()):\n",
    "    if ax.ndim == 1:\n",
    "        current_ax = ax[i]\n",
    "    else:\n",
    "        current_ax = ax[i // ax.shape[1]][i % ax.shape[1]]\n",
    "    current_ax.set_xticks(range(len(metrics_to_compare)))\n",
    "    current_ax.set_xticklabels(metrics_to_compare.values(), rotation=45)\n",
    "    current_ax.set_ylim(-0.1, 1.1)\n",
    "    current_ax.set_title(label)\n",
    "    if i == 0:\n",
    "        current_ax.set_ylabel(\"Spearman Correlation\")\n",
    "\n",
    "    for j, (metric, metric_label) in enumerate(metrics_to_compare.items()):\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "        for k, dataset in enumerate(datasets):\n",
    "            correlation = all_correlation_dfs[perturbation][dataset][metric][\"noise_level\"]\n",
    "            x_offset = k / len(datasets) * 0.6 - 0.3\n",
    "            all_x.append(x_offset + j)\n",
    "            all_y.append(correlation if np.isfinite(correlation) else 0)\n",
    "        current_ax.scatter(all_x, all_y, label=metric_label, color=to_descriptor_color(metric), s=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = f\"correlation_plots_{MAIN_METRIC_NAME}_{MAIN_CLASSIFIER_TYPE}_full.pdf\" if PLOT_FULL else f\"correlation_plots_{MAIN_METRIC_NAME}_{MAIN_CLASSIFIER_TYPE}_cropped.pdf\"\n",
    "Path(here() / f\".local/plots/\").mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(here() / f\".local/plots/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics vs Noise Level Plots\n",
    "\n",
    "Now, we plot the metrics against the noise level. These plots are intended to compare the expressiveness of different descriptors. They will go in the appendix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_metric_legend_name(metric_name):\n",
    "    \"\"\"Map metric names to legend names.\"\"\"\n",
    "    metric_legend_names = {\n",
    "        \"orbit_rbf\": \"Orbit RBF\",\n",
    "        \"degree_rbf\": \"Deg. RBF\", \n",
    "        \"spectral_rbf\": \"Spec. RBF\",\n",
    "        \"clustering_rbf\": \"Clust. RBF\",\n",
    "        \"gin_rbf\": \"GIN RBF\",\n",
    "        f\"{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\": \"PGS\",\n",
    "        f\"rbf_{MAIN_METRIC_NAME}\": \"RBF PGS\",\n",
    "        f\"orbit_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\": \"Orbit PGS\",\n",
    "        f\"degree_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\": \"Degree PGS\", \n",
    "        f\"spectral_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\": \"Spectral PGS\",\n",
    "        f\"clustering_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\": \"Clustering PGS\",\n",
    "        f\"gin_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\": \"GIN PGS\",\n",
    "    }\n",
    "    for classifier in classifiers_to_compare:\n",
    "        if classifier != MAIN_CLASSIFIER_TYPE:\n",
    "            metric_legend_names[f\"{classifier}_{MAIN_METRIC_NAME}\"] = f\"{classifier.upper()} PGS\"\n",
    "        \n",
    "    return metric_legend_names.get(metric_name, metric_name)\n",
    "\n",
    "def map_clf_metric_name(metric_name):\n",
    "    if metric_name == \"informedness\":\n",
    "        return \"Informedness\"\n",
    "    elif metric_name == \"jsd\":\n",
    "        return \"JSD\"\n",
    "    else:\n",
    "        return metric_name\n",
    "\n",
    "def plot_metrics_vs_noise_level(perturbations_to_plot, datasets_to_plot, metrics_to_plot, color_fn, ylabel):\n",
    "    \"\"\"Plot metrics vs noise level for different perturbations and datasets using seaborn relplot.\"\"\"\n",
    "    plot_data = []\n",
    "    \n",
    "    for perturbation, perturbation_label in perturbations_to_plot.items():\n",
    "        for dataset, dataset_label in datasets_to_plot.items():\n",
    "            correlation = all_correlation_dfs[perturbation][dataset][f'{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}']['noise_level']\n",
    "            \n",
    "            for metric, (metric_label, marker) in metrics_to_plot.items():\n",
    "                df_subset = all_dfs[perturbation][dataset]\n",
    "                for _, row in df_subset.iterrows():\n",
    "                    legend_name = map_metric_legend_name(metric)\n",
    "                    plot_data.append({\n",
    "                        'perturbation': perturbation_label,\n",
    "                        'dataset': dataset_label,\n",
    "                        'metric': legend_name,\n",
    "                        'metric_key': metric,\n",
    "                        'noise_level': row['noise_level'],\n",
    "                        'metric_value': row[metric],\n",
    "                        'marker_style': marker,\n",
    "                        'correlation': correlation\n",
    "                    })\n",
    "    \n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    if color_fn is not None:\n",
    "        unique_metrics = plot_df['metric_key'].unique()\n",
    "        color_mapping = {metric: color_fn(metric) for metric in unique_metrics}\n",
    "        \n",
    "        def to_hex(color):\n",
    "            if color is None:\n",
    "                return \"black\"\n",
    "            if isinstance(color, str):\n",
    "                return color\n",
    "            if hasattr(color, '__len__') and len(color) >= 3:\n",
    "                return f\"#{int(color[0]*255):02x}{int(color[1]*255):02x}{int(color[2]*255):02x}\"\n",
    "            return \"black\"\n",
    "        \n",
    "        color_mapping = {k: to_hex(v) for k, v in color_mapping.items()}\n",
    "        \n",
    "        legend_color_mapping = {}\n",
    "        for metric_key in unique_metrics:\n",
    "            legend_name = map_metric_legend_name(metric_key)\n",
    "            legend_color_mapping[legend_name] = color_mapping[metric_key]\n",
    "        \n",
    "        g = sns.relplot(\n",
    "            data=plot_df,\n",
    "            x=\"noise_level\",\n",
    "            y='metric_value', \n",
    "            col=\"perturbation\",\n",
    "            row=\"dataset\",\n",
    "            hue=\"metric\",\n",
    "            style=\"metric\",\n",
    "            kind=\"scatter\",\n",
    "            height=3,\n",
    "            aspect=0.8,\n",
    "            s=20,\n",
    "            alpha=0.8,\n",
    "            palette=legend_color_mapping,\n",
    "            facet_kws={'margin_titles': True, \"sharex\": False}\n",
    "        )\n",
    "    else:\n",
    "        g = sns.relplot(\n",
    "            data=plot_df,\n",
    "            x=\"noise_level\",\n",
    "            y='metric_value', \n",
    "            col=\"perturbation\",\n",
    "            row=\"dataset\",\n",
    "            hue=\"metric\",\n",
    "            kind=\"scatter\",\n",
    "            height=3,\n",
    "            aspect=0.8,\n",
    "            s=30,\n",
    "            alpha=0.8,\n",
    "            palette=\"colorblind\",\n",
    "            facet_kws={'margin_titles': True, \"sharex\": False}\n",
    "        )\n",
    "    \n",
    "    g.set_xlabels(\"Noise Level\")\n",
    "    g.set_ylabels(ylabel) \n",
    "    g.set(ylim=(-0.1, 1.05))\n",
    "    \n",
    "    g.set_titles(row_template='{row_name}', col_template='{col_name}')\n",
    "\n",
    "    for (row_val, col_val), ax in g.axes_dict.items():\n",
    "        correlation_row = plot_df[\n",
    "            (plot_df['dataset'] == row_val) & \n",
    "            (plot_df['perturbation'] == col_val)\n",
    "        ].iloc[0]\n",
    "        correlation = correlation_row['correlation']\n",
    "        \n",
    "        current_title = ax.get_title()\n",
    "        new_title = f\"{current_title}\\nPGS ρ = {correlation:.2f}\"\n",
    "        ax.set_title(new_title)\n",
    "\n",
    "    \n",
    "    sns.move_legend(g, \"lower center\", bbox_to_anchor=(0.5, 0.01), ncol=3, title=\"Metric\")\n",
    "    plt.tight_layout(rect=[0, 0.06, 1, 1])\n",
    "    return g.fig, g.axes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "perturbations_to_plot = OrderedDict([\n",
    "    (\"edge_deletion\", \"Edge Deletion\"), \n",
    "    (\"edge_rewiring\", \"Edge Rewiring\"), \n",
    "    (\"edge_swapping\", \"Edge Swapping\"), \n",
    "    (\"mixing\", \"Mixing\"), \n",
    "    (\"edge_addition\", \"Edge Addition\"\n",
    ")])\n",
    "\n",
    "datasets_to_plot = OrderedDict([\n",
    "    (\"planar\", \"Planar\"),\n",
    "    (\"lobster\", \"Lobster\"),\n",
    "    (\"proteins\", \"Proteins\"),\n",
    "    (\"sbm\", \"SBM\"),\n",
    "    (\"ego\", \"Ego\"),\n",
    "])\n",
    "\n",
    "metrics_to_plot = OrderedDict([\n",
    "    (f\"orbit_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", (\"Orbit PGS\", \"o\")),\n",
    "    (f\"degree_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", (\"Degree PGS\", \"o\")),\n",
    "    (f\"spectral_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", (\"Spectral PGS\", \"o\")),\n",
    "    (f\"clustering_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", (\"Clustering PGS\", \"o\")),\n",
    "    (f\"gin_{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", (\"GIN PGS\", \"o\")),\n",
    "    (f\"{MAIN_CLASSIFIER_TYPE}_{MAIN_METRIC_NAME}\", (\"PGS\", \"x\")),\n",
    "])\n",
    "\n",
    "fig, ax = plot_metrics_vs_noise_level(perturbations_to_plot, datasets_to_plot, metrics_to_plot, color_fn=to_descriptor_color, ylabel=\"PGS\")\n",
    "filename = f\"metrics_vs_noise_level_{MAIN_METRIC_NAME}_{MAIN_CLASSIFIER_TYPE}_full.pdf\" if PLOT_FULL else f\"metrics_vs_noise_level_{MAIN_METRIC_NAME}_{MAIN_CLASSIFIER_TYPE}_cropped.pdf\"\n",
    "Path(here() / f\".local/plots/\").mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(here() / f\".local/plots/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compare TabPFN against logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_to_compare = (\"lr\", \"tabpfn\")\n",
    "markers = (\"o\", \"x\")\n",
    "colors = ()\n",
    "\n",
    "perturbations_to_plot = OrderedDict([\n",
    "    (\"edge_deletion\", \"Edge Deletion\"), \n",
    "    (\"edge_rewiring\", \"Edge Rewiring\"), \n",
    "    (\"edge_swapping\", \"Edge Swapping\"), \n",
    "    (\"mixing\", \"Mixing\"), \n",
    "    (\"edge_addition\", \"Edge Addition\"\n",
    ")])\n",
    "\n",
    "datasets_to_plot = OrderedDict([\n",
    "    (\"planar\", \"Planar\"),\n",
    "    (\"lobster\", \"Lobster\"),\n",
    "    (\"proteins\", \"Proteins\"),\n",
    "    (\"sbm\", \"SBM\"),\n",
    "    (\"ego\", \"Ego\"),\n",
    "])\n",
    "\n",
    "metrics_to_plot = OrderedDict([\n",
    "    (f\"{classifier_name}_{MAIN_METRIC_NAME}\", (f\"{classifier_name.upper()} PGS\", marker)) for classifier_name, marker in zip(classifiers_to_compare, markers)\n",
    "])\n",
    "\n",
    "fig, ax = plot_metrics_vs_noise_level(perturbations_to_plot, datasets_to_plot, metrics_to_plot, rbf_lr_color, ylabel=\"PGS\")\n",
    "filename = f\"{classifiers_to_compare[0]}_vs_{classifiers_to_compare[1]}_full_{MAIN_METRIC_NAME}.pdf\" if PLOT_FULL else f\"{classifiers_to_compare[0]}_vs_{classifiers_to_compare[1]}_cropped_{MAIN_METRIC_NAME}.pdf\"\n",
    "fig.savefig(here() / f\".local/plots/{filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polygrapher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
